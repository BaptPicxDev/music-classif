{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70832d706acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnavigate\u001b[0m \u001b[1;31m# A python file i created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;31m# Utilities funcions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projets\\music-classif\\volumes\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_metrics'"
     ]
    }
   ],
   "source": [
    "# All the imports \n",
    "# Librairies\n",
    "import os # Help to get the path.\n",
    "import time # This librairy permit to calculate the duration of the main script.\n",
    "import shutil # Remove a dir with subdirs.\n",
    "import librosa\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib as mlp\n",
    "mlp.use(\"Agg\") # Set the environnement to avoid displaying figures.\n",
    "from keras.callbacks import History \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Avoid FutureWarning -> h5py from 'float' to 'np.float64'\n",
    "# My scripts \n",
    "import songs # A python file i created.\n",
    "import navigate # A python file i created.\n",
    "import utils # Utilities funcions.\n",
    "import model\n",
    "\n",
    "# Variables \n",
    "if(os.path.exists(\"src\")) :\n",
    "\tproject_path = str(navigate.get_actual_path()+\"\\\\src\") # This is the path to the project folder.\n",
    "else : \n",
    "\tproject_path = navigate.get_actual_path() # This is the path to the project folder.\n",
    "json_file = \"config.json\"\n",
    "tracks = \"tracks.csv\"\n",
    "my_json = None\n",
    "\n",
    "# utils.razJSON()\n",
    "# utils.createJSON(project_path, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(my_json != None) :\n",
    "    pass\n",
    "else :\n",
    "    my_json = utils.openJSON(json_file)\n",
    "optimizer = 'rmsprop' # rmsprop\n",
    "loss_func = 'mean_squared_error' #  Adams, mean_squared_error\n",
    "encoder_state = True\n",
    "start = time.clock()\n",
    "X_train, Y_train, X_test, Y_test = model.shapeDataDense(my_json, 0.9, encoder=encoder_state)\n",
    "end = time.clock() - start \n",
    "print(\"It takes : \",int(end/60),\" minutes.\")\n",
    "model_Dense = model.getDenseModel(X_train[0], len(Y_train[0]), optimizer, loss_func)\n",
    "model_Dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = int(len(X_train)/6)\n",
    "verbose = 1\n",
    "nfft = 0\n",
    "overlap = 0\n",
    "Fs = 0\n",
    "frequency = 0\n",
    "cats = 0\n",
    "start = time.clock()\n",
    "hist = History()\n",
    "model_Dense = model.fitModel(model_Dense, X_train, Y_train, X_test, Y_test, epochs, batch_size, verbose, hist)\n",
    "my_time = time.clock() - start \n",
    "print(\"It takes : \",int(my_time/60),\" seconds.\")\n",
    "scores, f1_score, precision, recall = model_Dense.evaluate(X_test, Y_test, verbose)\n",
    "print(\"Loss : \",int(scores[0]*100),\"% / Accuracy : \",int(scores[1]*100),\"%.\")\n",
    "utils.saveResults(my_json, model_Dense, X_train, X_test, Y_train, scores, epochs, batch_size, my_time, nfft, overlap, Fs, optimizer, loss_func, frequency, cats, encoder_state, 1)\n",
    "utils.printLossAccu(my_json, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(my_json != None) :\n",
    "    pass\n",
    "else :\n",
    "    my_json = utils.openJSON(json_file)\n",
    "encoder_state = True\n",
    "X_train, Y_train, X_test, Y_test, width, height = model.shapeData(my_json, 0.9, encoder=encoder_state)\n",
    "print('Total dataset :',len(X_train)+len(X_test))\n",
    "print(\"Len train set : \",len(X_train))\n",
    "print(\"Len test set : \",len(X_test))\n",
    "print(\"Shape entries : \",X_train.shape)\n",
    "print(\"Shape outputs : \",Y_train.shape)\n",
    "print(\"Image height : \",height)\n",
    "print(\"Image width : \",width)\n",
    "cats = [c[\"category_name\"] for c in model.shapeOutputs(my_json)]\n",
    "Fs, nfft, overlap, frequency = songs.getFreqOverlapNFFT(my_json)\n",
    "optimizer = 'rmsprop' # rmsprop\n",
    "loss_func = 'mean_squared_error' #  Adams, mean_squared_error\n",
    "print(\"Categories : \",cats)\n",
    "print(\"Original frequency =  \",frequency,\" Hz.\")\n",
    "print(\"Sample frequency =  \",Fs,\" Hz.\")\n",
    "print(\"NFFT points : \",nfft)\n",
    "print(\"Overlap = \",overlap)\n",
    "model_conv2D = model.getModel(len(Y_train[0]), width, height, optimizer, loss_func)\n",
    "model_conv2D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = int(len(X_train)/2)\n",
    "verbose = 1\n",
    "start = time.clock()\n",
    "hist = History()\n",
    "model_conv2D = model.fitModel(model_conv2D, X_train, Y_train, X_test, Y_test, epochs, batch_size, verbose, hist)\n",
    "my_time = time.clock() - start \n",
    "scores = model_conv2D.evaluate(X_test, Y_test, verbose)\n",
    "print(\"Loss : \",int(scores[0]*100),\"% / Accuracy : \",int(scores[1]*100),\"%.\")\n",
    "utils.saveResults(my_json, model_conv2D, X_train, X_test, Y_train, scores, epochs, batch_size, my_time, nfft, overlap, Fs, optimizer, loss_func, frequency, cats, encoder_state)\n",
    "utils.printLossAccu(my_json, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(my_json != None) :\n",
    "    pass\n",
    "else :\n",
    "    my_json = utils.openJSON(json_file)\n",
    "X_train, Y_train, X_test, Y_test, width, height = model.shapeDataConv2DGTZAN(my_json, 0.9)\n",
    "optimizer = 'rmsprop' # rmsprop\n",
    "loss_func = 'mean_squared_error' #  Adams, mean_squared_error\n",
    "model_conv2D = model.getConv2DModel1(len(Y_train[0]), width, height, optimizer, loss_func)\n",
    "model_conv2D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = int(len(X_train)/10)\n",
    "verbose = 1\n",
    "nfft = 0\n",
    "overlap = 0\n",
    "Fs = 0\n",
    "frequency = 0\n",
    "encoder_state = False\n",
    "cats = 0\n",
    "start = time.clock()\n",
    "hist = History()\n",
    "model_conv2D = model.fitModel(model_conv2D, X_train, Y_train, X_test, Y_test, epochs, batch_size, verbose, hist)\n",
    "my_time = time.clock() - start \n",
    "print(\"It takes : \",int(my_time/60),\" minutes.\")\n",
    "scores = model_conv2D.evaluate(X_test, Y_test, verbose)\n",
    "print(\"Loss : \",int(scores[0]*100),\"% / Accuracy : \",int(scores[1]*100),\"%.\")\n",
    "utils.saveResults(my_json, model_conv2D, X_train, X_test, Y_train, scores, epochs, batch_size, my_time, nfft, overlap, Fs, optimizer, loss_func, frequency, cats, encoder_state, 1)\n",
    "utils.printLossAccu(my_json, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
